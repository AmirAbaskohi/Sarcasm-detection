{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoZFPIr057or"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer , TfidfTransformer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FV1IUdLA6skU"
      },
      "source": [
        "dataset_path = '/content/drive/MyDrive/iSarcasm/train.En.csv'\n",
        "df = pd.read_csv(dataset_path)[[\"tweet\", \"sarcastic\"]]\n",
        "df = df[df['tweet'].notna()]\n",
        "X, y = df[[\"tweet\"]], df[[\"sarcastic\"]]"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ygWfHk8i7Haa",
        "outputId": "254331eb-ab35-414c-f2d0-e49f5c1a3e24"
      },
      "source": [
        "X.head()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The only thing I got from college is a caffein...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I love it when professors draw a big question ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Remember the hundred emails from companies whe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Today my pop-pop told me I was not “forced” to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@VolphanCarol @littlewhitty @mysticalmanatee I...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               tweet\n",
              "0  The only thing I got from college is a caffein...\n",
              "1  I love it when professors draw a big question ...\n",
              "2  Remember the hundred emails from companies whe...\n",
              "3  Today my pop-pop told me I was not “forced” to...\n",
              "4  @VolphanCarol @littlewhitty @mysticalmanatee I..."
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "WUGjFVjC7I9T",
        "outputId": "d96f7f93-83c4-40d2-ff6b-2466152d0843"
      },
      "source": [
        "y.head()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sarcastic\n",
              "0          1\n",
              "1          1\n",
              "2          1\n",
              "3          1\n",
              "4          1"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DjC5bPW7KFO",
        "outputId": "df8dc5fe-e356-4237-abd4-070a1024d592"
      },
      "source": [
        "y.value_counts()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sarcastic\n",
              "0            2600\n",
              "1             867\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFWNbcQX7OME",
        "outputId": "3a239282-fbed-4abe-b9e0-455816dcb025"
      },
      "source": [
        "count_vect = CountVectorizer()\n",
        "X_train_counts = count_vect.fit_transform(X['tweet'].values.astype('U'))\n",
        "X_train_counts.toarray()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "id": "Y9VvuGdF7jIz",
        "outputId": "2d561918-9833-4447-c979-c4b436d5c4f6"
      },
      "source": [
        "tfidf_transformer = TfidfTransformer(smooth_idf=True,use_idf=True)\n",
        "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
        "df_idf = pd.DataFrame(tfidf_transformer.idf_, index=count_vect.get_feature_names(),columns=[\"idf_weights\"]) \n",
        "df_idf.sort_values(by=['idf_weights'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idf_weights</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>the</th>\n",
              "      <td>1.853177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>to</th>\n",
              "      <td>2.034416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>and</th>\n",
              "      <td>2.156772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>my</th>\n",
              "      <td>2.422993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>of</th>\n",
              "      <td>2.492328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>holby</th>\n",
              "      <td>8.458474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hogs</th>\n",
              "      <td>8.458474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hog</th>\n",
              "      <td>8.458474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>homewreckermovie</th>\n",
              "      <td>8.458474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zywia0ex4u</th>\n",
              "      <td>8.458474</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10469 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  idf_weights\n",
              "the                  1.853177\n",
              "to                   2.034416\n",
              "and                  2.156772\n",
              "my                   2.422993\n",
              "of                   2.492328\n",
              "...                       ...\n",
              "holby                8.458474\n",
              "hogs                 8.458474\n",
              "hog                  8.458474\n",
              "homewreckermovie     8.458474\n",
              "zywia0ex4u           8.458474\n",
              "\n",
              "[10469 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zii0A2lx8ERc"
      },
      "source": [
        "def report_acc_cv(clf, X, y, model_name, cv=10, scoring='accuracy'):\n",
        "\n",
        "  acc = cross_val_score(clf, X, y, cv=cv, scoring='accuracy')\n",
        "  accb = cross_val_score(clf, X, y, cv=cv, scoring='balanced_accuracy')\n",
        "  f1 = cross_val_score(clf, X, y, cv=cv, scoring='f1')\n",
        "  p = cross_val_score(clf, X, y, cv=cv, scoring='precision')\n",
        "  r = cross_val_score(clf, X, y, cv=cv, scoring='recall')\n",
        "\n",
        "  print(model_name,\" accuracy is: %.2f%% +- %.2f%%\" %(np.mean(acc)*100,np.std(acc)*100))\n",
        "  print(model_name,\" balanced accuracy is: %.2f%% +- %.2f%%\" %(np.mean(accb)*100,np.std(accb)*100))\n",
        "  print(model_name,\" f1-score is: %.2f%% +- %.2f%%\" %(np.mean(f1)*100,np.std(f1)*100))\n",
        "  print(model_name,\" precision is: %.2f%% +- %.2f%%\" %(np.mean(p)*100,np.std(p)*100))\n",
        "  print(model_name,\" recall is: %.2f%% +- %.2f%%\" %(np.mean(r)*100,np.std(r)*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJ9KC0MM-AZ4"
      },
      "source": [
        "# Result with count vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcN4ont28u_o",
        "outputId": "ee192fe4-b3f9-45f0-83d5-b7fdcad83eb0"
      },
      "source": [
        "X_train = X_train_counts\n",
        "class_weight= {1: 3, 0: 1}\n",
        "\n",
        "clf = SVC(C=10, kernel='rbf', class_weight=class_weight)\n",
        "report_acc_cv(clf, X_train, y.values.ravel(), \"svm\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "svm  accuracy is: 73.41% +- 1.70%\n",
            "svm  balanced accuracy is: 52.60% +- 2.21%\n",
            "svm  f1-score is: 17.03% +- 5.43%\n",
            "svm  precision is: 38.72% +- 11.72%\n",
            "svm  recall is: 10.96% +- 3.58%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZJECA4GAYZP"
      },
      "source": [
        "# Result with TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTYauYch-xDY",
        "outputId": "99ed23a6-d6aa-452c-b299-67b3917f9f99"
      },
      "source": [
        "X_train = X_train_tfidf\n",
        "class_weight= {1: 3, 0: 1}\n",
        "\n",
        "clf = SVC(C=10, kernel='rbf', class_weight=class_weight)\n",
        "report_acc_cv(clf, X_train, y.values.ravel(), \"svm\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "svm  accuracy is: 75.17% +- 0.79%\n",
            "svm  balanced accuracy is: 52.08% +- 1.25%\n",
            "svm  f1-score is: 10.51% +- 4.12%\n",
            "svm  precision is: 51.95% +- 15.43%\n",
            "svm  recall is: 5.88% +- 2.39%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLDz2h7lF25l"
      },
      "source": [
        "# Result with BERT (Word Tokenization Format)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BSv-yz6JyY40",
        "outputId": "3893f5a2-2206-4bdb-ad8d-e5f24a89b1b6"
      },
      "source": [
        "!pip install bert-embedding\n",
        "!pip install mxnet-cu100\n",
        "!pip install sentence-transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
            "Requirement already satisfied: bert-embedding in /usr/local/lib/python3.7/dist-packages (1.0.1)\n",
            "Collecting numpy==1.14.6\n",
            "  Using cached numpy-1.14.6-cp37-cp37m-manylinux1_x86_64.whl (13.8 MB)\n",
            "Requirement already satisfied: typing==3.6.6 in /usr/local/lib/python3.7/dist-packages (from bert-embedding) (3.6.6)\n",
            "Requirement already satisfied: gluonnlp==0.6.0 in /usr/local/lib/python3.7/dist-packages (from bert-embedding) (0.6.0)\n",
            "Requirement already satisfied: mxnet==1.4.0 in /usr/local/lib/python3.7/dist-packages (from bert-embedding) (1.4.0)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from mxnet==1.4.0->bert-embedding) (0.8.4)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet==1.4.0->bert-embedding) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->mxnet==1.4.0->bert-embedding) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->mxnet==1.4.0->bert-embedding) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->mxnet==1.4.0->bert-embedding) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->mxnet==1.4.0->bert-embedding) (1.24.3)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution -umpy (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
            "    Found existing installation: numpy 1.21.4\n",
            "    Uninstalling numpy-1.21.4:\n",
            "      Successfully uninstalled numpy-1.21.4\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.3.post1 requires numpy<1.20,>=1.16.0, but you have numpy 1.14.6 which is incompatible.\n",
            "xarray 0.18.2 requires numpy>=1.17, but you have numpy 1.14.6 which is incompatible.\n",
            "transformers 4.12.5 requires numpy>=1.17, but you have numpy 1.14.6 which is incompatible.\n",
            "tifffile 2021.11.2 requires numpy>=1.15.1, but you have numpy 1.14.6 which is incompatible.\n",
            "spacy 2.2.4 requires numpy>=1.15.0, but you have numpy 1.14.6 which is incompatible.\n",
            "seaborn 0.11.2 requires numpy>=1.15, but you have numpy 1.14.6 which is incompatible.\n",
            "scikit-image 0.18.3 requires numpy>=1.16.5, but you have numpy 1.14.6 which is incompatible.\n",
            "pywavelets 1.2.0 requires numpy>=1.17.3, but you have numpy 1.14.6 which is incompatible.\n",
            "pymc3 3.11.4 requires numpy>=1.15.0, but you have numpy 1.14.6 which is incompatible.\n",
            "pyerfa 2.0.0.1 requires numpy>=1.17, but you have numpy 1.14.6 which is incompatible.\n",
            "pyarrow 3.0.0 requires numpy>=1.16.6, but you have numpy 1.14.6 which is incompatible.\n",
            "plotnine 0.6.0 requires numpy>=1.16.0, but you have numpy 1.14.6 which is incompatible.\n",
            "pandas 1.1.5 requires numpy>=1.15.4, but you have numpy 1.14.6 which is incompatible.\n",
            "numba 0.51.2 requires numpy>=1.15, but you have numpy 1.14.6 which is incompatible.\n",
            "mxnet-cu100 1.8.0.post0 requires numpy<2.0.0,>1.16.0, but you have numpy 1.14.6 which is incompatible.\n",
            "librosa 0.8.1 requires numpy>=1.15.0, but you have numpy 1.14.6 which is incompatible.\n",
            "kapre 0.3.6 requires numpy>=1.18.5, but you have numpy 1.14.6 which is incompatible.\n",
            "jaxlib 0.1.71+cuda111 requires numpy>=1.18, but you have numpy 1.14.6 which is incompatible.\n",
            "jax 0.2.25 requires numpy>=1.18, but you have numpy 1.14.6 which is incompatible.\n",
            "imgaug 0.2.9 requires numpy>=1.15.0, but you have numpy 1.14.6 which is incompatible.\n",
            "fbprophet 0.7.1 requires numpy>=1.15.4, but you have numpy 1.14.6 which is incompatible.\n",
            "fastai 1.0.61 requires numpy>=1.15, but you have numpy 1.14.6 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "cvxpy 1.0.31 requires numpy>=1.15, but you have numpy 1.14.6 which is incompatible.\n",
            "cupy-cuda111 9.4.0 requires numpy<1.24,>=1.17, but you have numpy 1.14.6 which is incompatible.\n",
            "blis 0.4.1 requires numpy>=1.15.0, but you have numpy 1.14.6 which is incompatible.\n",
            "astropy 4.3.1 requires numpy>=1.17, but you have numpy 1.14.6 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.14.6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
            "Requirement already satisfied: mxnet-cu100 in /usr/local/lib/python3.7/dist-packages (1.8.0.post0)\n",
            "Collecting numpy<2.0.0,>1.16.0\n",
            "  Using cached numpy-1.21.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet-cu100) (2.23.0)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from mxnet-cu100) (0.8.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu100) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu100) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu100) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu100) (3.0.4)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution -umpy (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
            "    Found existing installation: numpy 1.14.6\n",
            "    Uninstalling numpy-1.14.6:\n",
            "      Successfully uninstalled numpy-1.14.6\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.3.post1 requires numpy<1.20,>=1.16.0, but you have numpy 1.21.4 which is incompatible.\n",
            "mxnet 1.4.0 requires numpy<1.15.0,>=1.8.2, but you have numpy 1.21.4 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "bert-embedding 1.0.1 requires numpy==1.14.6, but you have numpy 1.21.4 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.21.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.7/dist-packages (2.1.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.11.1+cu111)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.62.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.0.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.2.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.1.96)\n",
            "Requirement already satisfied: tokenizers>=0.10.3 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.10.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.21.4)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.10.0+cu111)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.12.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.10.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.0.46)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (4.8.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (3.0.0)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6lJYHfy5-9z"
      },
      "source": [
        "import re\n",
        "\n",
        "def embeddToBERT(text):\n",
        "    sentences = re.split('!|\\?|\\.',text)\n",
        "    sentences = list(filter(None, sentences)) \n",
        "\n",
        "    if bert_version == 'WORD':\n",
        "        result = bert(sentences, 'avg') # avg is refer to handle OOV\n",
        "    \n",
        "        bert_vocabs_of_sentence = []\n",
        "        for sentence in range(len(result)):\n",
        "            for word in range(len(result[sentence][1])):\n",
        "                bert_vocabs_of_sentence.append(result[sentence][1][word])\n",
        "        feature = [mean(x) for x in zip(*bert_vocabs_of_sentence)]\n",
        "\n",
        "    elif bert_version == 'SENTENCE':\n",
        "        result = bert_transformers.encode(sentences)\n",
        "        feature = [mean(x) for x in zip(*result)]\n",
        "  \n",
        "    return feature"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-JvbiFz6SIN"
      },
      "source": [
        "import mxnet as mx\n",
        "from bert_embedding import BertEmbedding\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import itertools\n",
        "\n",
        "def mean(z):\n",
        "    return sum(itertools.chain(z))/len(z)\n",
        "\n",
        "bert_version = 'WORD'\n",
        "\n",
        "ctx = mx.gpu(0)\n",
        "bert = BertEmbedding(ctx=ctx)\n",
        "\n",
        "bert_word_training_features = X['tweet'].apply(embeddToBERT)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jmm2aSFFxjR"
      },
      "source": [
        "feature = [x for x in bert_word_training_features.transpose()]\n",
        "bert_word_training_features = np.asarray(feature)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vG0D5A6o6kYQ",
        "outputId": "77957863-3199-4894-a548-27807b2b7ac5"
      },
      "source": [
        "class_weight= {1: 3, 0: 1}\n",
        "\n",
        "clf = SVC(C=10, kernel='rbf', class_weight=class_weight)\n",
        "report_acc_cv(clf, bert_word_training_features, y.values.ravel(), \"svm\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "svm  accuracy is: 71.42% +- 1.90%\n",
            "svm  balanced accuracy is: 58.42% +- 2.29%\n",
            "svm  f1-score is: 36.16% +- 4.01%\n",
            "svm  precision is: 41.05% +- 4.63%\n",
            "svm  recall is: 32.41% +- 3.97%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7ERqnMgKTL2"
      },
      "source": [
        "# Result with Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUY_A7eFRPRE"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize \n",
        "\n",
        "def embeddToWord2Vec(text):\n",
        "    words = word_tokenize(text)\n",
        "    \n",
        "    if embedding is 'WORD2VEC_WITH_STOP':\n",
        "        result = [w2v_with_stop_model.wv[w] for w in words if w in w2v_with_stop_model.wv.vocab]\n",
        "    else:\n",
        "        result = [w2v_no_stop_model.wv[w] for w in words if w in w2v_no_stop_model.wv.vocab]\n",
        "    \n",
        "    feature = [mean(x) for x in zip(*result)]\n",
        "    return feature\n",
        "\n",
        "def wordTokenize(text):\n",
        "  return word_tokenize(text)"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqeeAqC6R4r3"
      },
      "source": [
        "embedding = 'WORD2VEC_WITH_STOP'"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxwDk5B2SDMW"
      },
      "source": [
        "import gensim\n",
        "\n",
        "words = X['tweet'].apply(wordTokenize)\n",
        "w2v_with_stop_model = gensim.models.Word2Vec(words, min_count = 2, size = 100, window = 5) "
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFN_zjv_SRoF"
      },
      "source": [
        "word2vec_with_stop_training_features = X['tweet'].apply(embeddToWord2Vec)\n",
        "\n",
        "feature = []\n",
        "deleted_indexes = []\n",
        "i = 0\n",
        "for x in word2vec_with_stop_training_features.transpose():\n",
        "  if x != []:\n",
        "    feature.append(x)\n",
        "  else:\n",
        "    deleted_indexes.append(i)\n",
        "  i += 1\n",
        "word2vec_with_stop_training_features = np.asarray(feature)"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41qTM270Tc4v",
        "outputId": "5090d84f-34a4-4f66-9a1f-06305e622477"
      },
      "source": [
        "class_weight= {1: 3, 0: 1}\n",
        "\n",
        "clf = SVC(C=10, kernel='rbf', class_weight=class_weight)\n",
        "report_acc_cv(clf, word2vec_with_stop_training_features, y.drop(deleted_indexes).values.ravel(), \"svm\")"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "svm  accuracy is: 30.71% +- 2.63%\n",
            "svm  balanced accuracy is: 50.58% +- 1.57%\n",
            "svm  f1-score is: 39.41% +- 1.48%\n",
            "svm  precision is: 25.23% +- 0.65%\n",
            "svm  recall is: 90.33% +- 7.92%\n"
          ]
        }
      ]
    }
  ]
}