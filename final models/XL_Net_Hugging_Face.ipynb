{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XL_Net_Hugging_Face.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4ZXYkHX1h9f",
        "outputId": "5638d35c-9141-467b-f320-4cff5d408cc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Install required packages\n",
        "\n",
        "!pip install transformers\n",
        "# !pip install datasets\n",
        "# !pip install fairseq\n",
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.16.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required packages\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "from numpy.lib.function_base import average\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import copy\n",
        "import collections\n",
        "import time\n",
        "import pickle\n",
        "\n",
        "from transformers import BertConfig, BertTokenizer, BertweetTokenizer, RobertaTokenizer, AlbertTokenizer, DistilBertTokenizer, XLMRobertaTokenizer, XLNetTokenizer, T5Tokenizer\n",
        "from transformers import BertModel\n",
        "\n",
        "from transformers import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from transformers import AutoTokenizer, XLMRobertaTokenizer\n",
        "from transformers import AutoModelForSequenceClassification, BertForSequenceClassification, DistilBertForSequenceClassification, RobertaForSequenceClassification, AlbertForSequenceClassification, XLMRobertaForSequenceClassification, XLNetForSequenceClassification, T5Model\n",
        "from transformers import TrainingArguments\n",
        "from transformers import Trainer\n",
        "# from fairseq.models.roberta import XLMRModel\n",
        "\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "J5aMHjRBP40D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7dHt6BRLoSy",
        "outputId": "44bdf3d3-314d-492e-c660-10d6325524e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SarcasimDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    \n",
        "## Test Dataset\n",
        "class SarcasimTestDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        return item\n",
        "    def __len__(self):\n",
        "        return len(self.encodings)"
      ],
      "metadata": {
        "id": "gejAk5MYLeFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(p):\n",
        "    pred, labels = p\n",
        "    pred = np.argmax(pred, axis=1)\n",
        "\n",
        "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
        "    recall = recall_score(y_true=labels, y_pred=pred, average='weighted')\n",
        "    precision = precision_score(y_true=labels, y_pred=pred, average='weighted')\n",
        "    f1 = f1_score(labels, pred, average='weighted')\n",
        "\n",
        "    return {\"accuracy\": accuracy,\"f1_score\":f1, \"recall\": recall, 'precision': precision}"
      ],
      "metadata": {
        "id": "hdF9u-OtLkYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from random import sample, random, shuffle\n",
        "from math import ceil\n",
        "import json\n",
        "\n",
        "class TextMutant():\n",
        "    def __init__(self):\n",
        "        synm_filepath = '/content/drive/MyDrive/DataLab/sarcasm/crawler/synm3.json'\n",
        "\n",
        "        with open(synm_filepath) as json_file:\n",
        "            self.synoynms = json.load(json_file)\n",
        "    \n",
        "    def remove_words(self, sentence, mode = \"k-random\", k = 0.1, prob = 0.1):\n",
        "        word_list = sentence.split()\n",
        "        new_words = []\n",
        "        if mode == \"prob\":\n",
        "            for i in word_list:\n",
        "                if (random() < prob):\n",
        "                    continue\n",
        "                new_words.append(i)\n",
        "        if mode == \"k-random\":\n",
        "            num = round(len(word_list) * k)\n",
        "            random_index = sample(list(range(len(word_list))), num)\n",
        "            new_words = list( word_list[i] for i in range(len(word_list)) if i not in random_index )\n",
        "        return \" \".join(new_words)\n",
        "\n",
        "    def shuffle_words(self, sentence, prob = 0.1):\n",
        "        word_list = sentence.split()\n",
        "        indexes = list(range(len(word_list)))\n",
        "        if (random() < prob):\n",
        "            shuffle(indexes)\n",
        "        new_words = list( word_list[i] for i in indexes )\n",
        "        return \" \".join(new_words)\n",
        "    \n",
        "    def replace_words(self, sentence, mode = \"k-random\", k = 0.1, prob = 0.1):\n",
        "        word_list = sentence.split()\n",
        "        new_words = []\n",
        "        if mode == \"prob\":\n",
        "            for i in word_list:\n",
        "                self.synoynms.setdefault(i, [])\n",
        "                if (random() < prob and len(self.synoynms[i]) > 0):\n",
        "                    new_words.append(sample(self.synoynms[i], 1)[0])\n",
        "                    continue\n",
        "                new_words.append(i)\n",
        "        if mode == \"k-random\":\n",
        "            num = round(len(word_list) * k)\n",
        "            indexes = list(range(len(word_list)))\n",
        "            shuffle(indexes)\n",
        "            new_words = word_list[:]\n",
        "            for i in indexes:\n",
        "                self.synoynms.setdefault(word_list[i], [])\n",
        "                if (num > 0 and len(self.synoynms[word_list[i]]) > 0):\n",
        "                    new_words[i] = sample(self.synoynms[word_list[i]], 1)[0]\n",
        "                    num -= 1\n",
        "        return \" \".join(new_words)\n",
        "\n",
        "    def create_new_sentence(self, sentence, flags,  shuffle_prob = 1, replace_k = 0.5, remove_k = 0.3):\n",
        "      if flags[0] == '1':\n",
        "        sentence = self.remove_words(sentence, k = remove_k)\n",
        "      if flags[1] == '1':\n",
        "        sentence = self.replace_words(sentence, k = replace_k)\n",
        "      if flags[2] == '1':\n",
        "        sentence = self.shuffle_words(sentence, prob=shuffle_prob)\n",
        "      return sentence\n",
        "    \n",
        "    def create_new_dataset(self, dataset, flags):\n",
        "      dataset_copy = dataset.copy()\n",
        "      for i in range(len(dataset['tweet'])):\n",
        "        dataset_copy['tweet'].iloc[i] = self.create_new_sentence(dataset_copy['tweet'].iloc[i], flags)\n",
        "      return dataset_copy"
      ],
      "metadata": {
        "id": "TmexAhE6Lmda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mutator = TextMutant()"
      ],
      "metadata": {
        "id": "D4g33-RTL1tE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test\n",
        "dataset_test = pd.read_csv('/content/drive/MyDrive/DataLab/sarcasm/FinalDataset/task_A_En_test.csv')\n",
        "print(len(dataset_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6Q2tCouL4vT",
        "outputId": "dc5e51a2-6187-42ad-f110-dd38bf679252"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/DataLab/sarcasm/FinalDataset/train.En.csv')[['tweet', 'sarcastic']]\n",
        "df = df.dropna(subset=['tweet'])\n",
        "# df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "df2 = pd.read_csv('/content/drive/MyDrive/DataLab/sarcasm/FinalDataset/data5.csv')[['tweet', 'sarcastic']]\n",
        "# df2 = df2.rename(columns={\"label\":\"sarcastic\"})\n",
        "df2 = df2.dropna(subset=['tweet'])\n",
        "# df2 = df2.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "df = pd.concat([df, df2]).reset_index(drop=True)\n",
        "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "X-Fq-63VL7J_",
        "outputId": "13948e33-9698-4531-dcba-2a3fc0f6b1c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6ab8be44-21e1-4312-b2ef-46ccda36a186\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>was It the</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Their website doesn't seem to mention Axa nor ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Imagine not liking football 🤣</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>just class Match is play to</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>guys one of want know I those You</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6929</th>\n",
              "      <td>He basically @DanielIngolfur communist. was I ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6930</th>\n",
              "      <td>a while, multiple in that still once Tatiana #...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6931</th>\n",
              "      <td>one! #podcasts next forward fun. Was the</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6932</th>\n",
              "      <td>at to have taste window think outside the it f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6933</th>\n",
              "      <td>do people with clear skin feel accomplished?? ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6934 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ab8be44-21e1-4312-b2ef-46ccda36a186')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6ab8be44-21e1-4312-b2ef-46ccda36a186 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6ab8be44-21e1-4312-b2ef-46ccda36a186');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                  tweet  sarcastic\n",
              "0                                            was It the          1\n",
              "1     Their website doesn't seem to mention Axa nor ...          0\n",
              "2                         Imagine not liking football 🤣          1\n",
              "3                           just class Match is play to          0\n",
              "4                     guys one of want know I those You          0\n",
              "...                                                 ...        ...\n",
              "6929  He basically @DanielIngolfur communist. was I ...          1\n",
              "6930  a while, multiple in that still once Tatiana #...          0\n",
              "6931           one! #podcasts next forward fun. Was the          0\n",
              "6932  at to have taste window think outside the it f...          0\n",
              "6933  do people with clear skin feel accomplished?? ...          1\n",
              "\n",
              "[6934 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = df['tweet']\n",
        "y_train = df['sarcastic']\n",
        "X_test = dataset_test['text']\n",
        "y_test = dataset_test['sarcastic']"
      ],
      "metadata": {
        "id": "zFH2PiFtL-jF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X_train))\n",
        "print(len(y_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-ftUKf-MBdn",
        "outputId": "0e58e21f-579f-4045-9768-7f29288daae0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6934\n",
            "6934\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.tolist()\n",
        "X_test = X_test.tolist()\n",
        "y_train = y_train.tolist()\n",
        "y_test = y_test.tolist()"
      ],
      "metadata": {
        "id": "L93nYmL0MDAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model\n",
        "model_name = 'detecting-sarcasim'\n",
        "task='sentiment'\n",
        "MODEL = 'xlnet-base-cased'\n",
        "\n",
        "tokenizer = XLNetTokenizer.from_pretrained(MODEL,num_labels=2, loss_function_params={\"weight\": [0.75, 0.25]})\n",
        "\n",
        "# tokenize\n",
        "train_encodings = tokenizer(X_train, truncation=True, padding=True,return_tensors = 'pt')\n",
        "# test_encodings = tokenizer(X_test,truncation=True, padding=True,return_tensors = 'pt')\n",
        "\n",
        "# change to dataset\n",
        "train_dataset = SarcasimDataset(train_encodings, y_train)\n",
        "# test_dataset = SarcasimDataset(test_encodings, y_test)\n",
        "\n",
        "# trainer args\n",
        "training_args = TrainingArguments(\n",
        "  output_dir='./res', num_train_epochs=5, per_device_train_batch_size=32, warmup_steps=500, weight_decay=0.01,logging_dir='./logs4'\n",
        "  )\n",
        "\n",
        "\n",
        "# model\n",
        "model = XLNetForSequenceClassification.from_pretrained(MODEL)\n",
        "# model.save_pretrained(MODEL)\n",
        "\n",
        "# train\n",
        "trainer = Trainer(\n",
        "    model = model,\n",
        "    args = training_args,\n",
        "    train_dataset = train_dataset,\n",
        "    # eval_dataset=test_dataset,\n",
        "    compute_metrics = compute_metrics,\n",
        "  )\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CHrOV8P3MEeP",
        "outputId": "c81ddf88-c9a0-406d-badc-0f03193fadc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/xlnet-base-cased/resolve/main/spiece.model from cache at /root/.cache/huggingface/transformers/df73bc9f8d13bf2ea4dab95624895e45a550a0f0a825e41fc25440bf367ee3c8.d93497120e3a865e2970f26abdf7bf375896f97fde8b874b70909592a6c785c9\n",
            "loading file https://huggingface.co/xlnet-base-cased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/xlnet-base-cased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/xlnet-base-cased/resolve/main/tokenizer_config.json from cache at None\n",
            "loading file https://huggingface.co/xlnet-base-cased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/46f47734f3dcaef7e236b9a3e887f27814e18836a8db7e6a49148000058a1a54.2a683f915238b4f560dab0c724066cf0a7de9a851e96b0fb3a1e7f0881552f53\n",
            "loading configuration file https://huggingface.co/xlnet-base-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/06bdb0f5882dbb833618c81c3b4c996a0c79422fa2c95ffea3827f92fc2dba6b.da982e2e596ec73828dbae86525a1870e513bd63aae5a2dc773ccc840ac5c346\n",
            "Model config XLNetConfig {\n",
            "  \"_name_or_path\": \"xlnet-base-cased\",\n",
            "  \"architectures\": [\n",
            "    \"XLNetLMHeadModel\"\n",
            "  ],\n",
            "  \"attn_type\": \"bi\",\n",
            "  \"bi_data\": false,\n",
            "  \"bos_token_id\": 1,\n",
            "  \"clamp_len\": -1,\n",
            "  \"d_head\": 64,\n",
            "  \"d_inner\": 3072,\n",
            "  \"d_model\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"end_n_top\": 5,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"ff_activation\": \"gelu\",\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"mem_len\": null,\n",
            "  \"model_type\": \"xlnet\",\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"pad_token_id\": 5,\n",
            "  \"reuse_len\": null,\n",
            "  \"same_length\": false,\n",
            "  \"start_n_top\": 5,\n",
            "  \"summary_activation\": \"tanh\",\n",
            "  \"summary_last_dropout\": 0.1,\n",
            "  \"summary_type\": \"last\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 250\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.16.2\",\n",
            "  \"untie_r\": true,\n",
            "  \"use_mems_eval\": true,\n",
            "  \"use_mems_train\": false,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "loading configuration file https://huggingface.co/xlnet-base-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/06bdb0f5882dbb833618c81c3b4c996a0c79422fa2c95ffea3827f92fc2dba6b.da982e2e596ec73828dbae86525a1870e513bd63aae5a2dc773ccc840ac5c346\n",
            "Model config XLNetConfig {\n",
            "  \"architectures\": [\n",
            "    \"XLNetLMHeadModel\"\n",
            "  ],\n",
            "  \"attn_type\": \"bi\",\n",
            "  \"bi_data\": false,\n",
            "  \"bos_token_id\": 1,\n",
            "  \"clamp_len\": -1,\n",
            "  \"d_head\": 64,\n",
            "  \"d_inner\": 3072,\n",
            "  \"d_model\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"end_n_top\": 5,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"ff_activation\": \"gelu\",\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"mem_len\": null,\n",
            "  \"model_type\": \"xlnet\",\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"pad_token_id\": 5,\n",
            "  \"reuse_len\": null,\n",
            "  \"same_length\": false,\n",
            "  \"start_n_top\": 5,\n",
            "  \"summary_activation\": \"tanh\",\n",
            "  \"summary_last_dropout\": 0.1,\n",
            "  \"summary_type\": \"last\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 250\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.16.2\",\n",
            "  \"untie_r\": true,\n",
            "  \"use_mems_eval\": true,\n",
            "  \"use_mems_train\": false,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/xlnet-base-cased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9461853998373b0b2f8ef8011a13b62a2c5f540b2c535ef3ea46ed8a062b16a9.3e214f11a50e9e03eb47535b58522fc3cc11ac67c120a9450f6276de151af987\n",
            "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.bias', 'lm_loss.weight']\n",
            "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'logits_proj.bias', 'sequence_summary.summary.weight', 'sequence_summary.summary.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 6934\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1085\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1085' max='1085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1085/1085 34:12, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.580400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.345300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./res/checkpoint-500\n",
            "Configuration saved in ./res/checkpoint-500/config.json\n",
            "Model weights saved in ./res/checkpoint-500/pytorch_model.bin\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n",
            "Saving model checkpoint to ./res/checkpoint-1000\n",
            "Configuration saved in ./res/checkpoint-1000/config.json\n",
            "Model weights saved in ./res/checkpoint-1000/pytorch_model.bin\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1085, training_loss=0.43560445231776085, metrics={'train_runtime': 2054.341, 'train_samples_per_second': 16.876, 'train_steps_per_second': 0.528, 'total_flos': 2662106059190160.0, 'train_loss': 0.43560445231776085, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_encodings = tokenizer(X_test, truncation=True, padding=True,return_tensors = 'pt')\n",
        "test_dataset = SarcasimDataset(test_encodings, y_test)"
      ],
      "metadata": {
        "id": "lEpVrhwMMWsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = trainer.predict(test_dataset)"
      ],
      "metadata": {
        "id": "QUiCWAIlM2sA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "outputId": "31477a52-95db-4091-818f-7247123c3f15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1400\n",
            "  Batch size = 8\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  import sys\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='175' max='175' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [175/175 00:38]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds.predictions"
      ],
      "metadata": {
        "id": "Xy76njI1M3Ne",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bad598e2-fe91-49e3-9af0-a675b60c847f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.9014605 , -0.5506527 ],\n",
              "       [ 3.1959937 , -4.0229497 ],\n",
              "       [ 1.73607   , -1.318895  ],\n",
              "       ...,\n",
              "       [ 3.1608338 , -3.446867  ],\n",
              "       [-0.01974405,  0.5739856 ],\n",
              "       [ 1.7562745 , -1.2952605 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = np.argmax(preds.predictions[:, 0:2], axis=-1)\n",
        "f = [0, 0, 0]\n",
        "for val in preds:\n",
        "  if val == 0:\n",
        "    f[0] += 1\n",
        "  elif val == 1:\n",
        "    f[1] += 1\n",
        "  else:\n",
        "    f[2] += 1\n",
        "print(f)"
      ],
      "metadata": {
        "id": "-HZyKhuwM5Ma",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b567ddef-3a83-438b-a18d-d3473e061090"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1052, 348, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f = open('/content/drive/MyDrive/DataLab/sarcasm/FinalDataset/result/xlnet-rs-data5', 'w')\n",
        "\n",
        "\n",
        "for pred in preds:\n",
        "  f.write(str(pred) + \"\\n\")\n",
        "\n",
        "f.close()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "g5w-BlVQM6-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# f = open('/content/drive/MyDrive/DataLab/sarcasm/FinalDataset/result/data4_res', 'r')\n",
        "# content = f.read()\n",
        "# predict_label = content.split(\"\\n\")\n",
        "actual_label = pd.read_csv('/content/drive/MyDrive/DataLab/sarcasm/FinalDataset/task_A_En_test.csv')['sarcastic'].tolist()"
      ],
      "metadata": {
        "id": "_IJfbtV2M_bU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score(actual_label,preds)"
      ],
      "metadata": {
        "id": "aDnmsWHUNBl0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "465e55cc-60c0-4063-dabe-de8b31445a12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.26277372262773724"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    }
  ]
}