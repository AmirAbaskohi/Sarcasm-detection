{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRqAE3nKaAyY",
        "outputId": "93eee8d4-f131-4152-de24-fd7719f863e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.16.1-py3-none-any.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 7.9 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 55.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting tokenizers!=0.11.3,>=0.10.1\n",
            "  Downloading tokenizers-0.11.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 37.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 68.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 6.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.11.4 transformers-4.16.1\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rpea3Py6aZM6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/cleaned_dataset.csv')\n",
        "sarcastic = df[df['sarcastic'] == 1]\n",
        "non_sarcastic = df[df['sarcastic'] == 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "XsQJQ6VgFhYQ",
        "outputId": "2336bf1b-6bc9-4b9d-859b-0ed3db3a654f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2b1d416b-fe0b-401b-b15c-9a4321c07785\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>the only thing i get from college be a caffein...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i love it when professor draw a big question m...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>remember the hundred email from company when c...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>today my pop pop tell me i be not force to go ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i do too and i also report cancun cruz not wor...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2b1d416b-fe0b-401b-b15c-9a4321c07785')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2b1d416b-fe0b-401b-b15c-9a4321c07785 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2b1d416b-fe0b-401b-b15c-9a4321c07785');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                               tweet  sarcastic\n",
              "0  the only thing i get from college be a caffein...          1\n",
              "1  i love it when professor draw a big question m...          1\n",
              "2  remember the hundred email from company when c...          1\n",
              "3  today my pop pop tell me i be not force to go ...          1\n",
              "4  i do too and i also report cancun cruz not wor...          1"
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sarcastic.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "BXnACuhwFi_z",
        "outputId": "3c0256a3-578f-4d94-9936-b14bc41f2312"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-bbaa21a1-3c33-4ba0-87d1-82bfec08a7ad\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>867</th>\n",
              "      <td>i always think go braless be a good idea until...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>868</th>\n",
              "      <td>life be so much good with a heating blanket</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>869</th>\n",
              "      <td>sometimes i just go through my phone and look ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>870</th>\n",
              "      <td>be not back in the state for even 5 minute bef...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>871</th>\n",
              "      <td>in desperate need of and i can not stress this...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bbaa21a1-3c33-4ba0-87d1-82bfec08a7ad')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bbaa21a1-3c33-4ba0-87d1-82bfec08a7ad button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bbaa21a1-3c33-4ba0-87d1-82bfec08a7ad');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                 tweet  sarcastic\n",
              "867  i always think go braless be a good idea until...          0\n",
              "868        life be so much good with a heating blanket          0\n",
              "869  sometimes i just go through my phone and look ...          0\n",
              "870  be not back in the state for even 5 minute bef...          0\n",
              "871  in desperate need of and i can not stress this...          0"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "non_sarcastic.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aqi87Ma8ag28"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "  def __init__(self, df):\n",
        "    super().__init__()\n",
        "\n",
        "    self.data_list = []\n",
        "    self.end_of_text_token = \" <|endoftext|> \"\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "      data_str = f\"{row[0]}{self.end_of_text_token}\"\n",
        "      self.data_list.append(data_str)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data_list)\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    return self.data_list[item]\n",
        "\n",
        "\n",
        "dataset_sarcastic = MyDataset(sarcastic)\n",
        "dataset_non_sarcastic = MyDataset(non_sarcastic)\n",
        "data_loader_sarcastic = DataLoader(dataset_sarcastic, batch_size=1, shuffle=True)\n",
        "data_loader_non_sarcastic = DataLoader(dataset_non_sarcastic, batch_size=1, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_R5mM5YHeNx_",
        "outputId": "b980df7a-456b-4885-9aba-272898135a44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "device = 'cpu'\n",
        "if torch.cuda.is_available():\n",
        "\tdevice = 'cuda'\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KEIlL8s5f4Oi"
      },
      "outputs": [],
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2-medium')\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2-medium')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQFSqNg_xZUZ"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "\n",
        "gc.collect()\n",
        "\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzgxWbg0gBV_"
      },
      "outputs": [],
      "source": [
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-09Ig4TgL7E"
      },
      "outputs": [],
      "source": [
        "def train(epochs, data_loader, batch_size, tokenizer, model, device):\t\n",
        "  batch_counter = 0\n",
        "  sum_loss = 0.0\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    print (f'Running {epoch+1} epoch')\n",
        "\n",
        "    for idx, txt in enumerate(data_loader):\n",
        "      txt = torch.tensor(tokenizer.encode(txt[0]))\n",
        "      txt = txt.unsqueeze(0).to(device)\n",
        "      outputs = model(txt, labels=txt)\n",
        "      loss, _ = outputs[:2]\n",
        "      loss.backward()\n",
        "      sum_loss += loss.data\n",
        "\n",
        "      if idx%batch_size==0:\n",
        "        batch_counter += 1\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        model.zero_grad()\n",
        "\n",
        "      if batch_counter == 10:\n",
        "        print(f\"Total Loss is {sum_loss}\")\n",
        "        batch_counter = 0\n",
        "        sum_loss = 0.0\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9z0mTU8fgxEh",
        "outputId": "3ce0275a-ba23-44c6-e3d9-a89de9ad6a29"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "from transformers import AdamW, get_cosine_with_hard_restarts_schedule_with_warmup\n",
        "\n",
        "model.train()\n",
        "optimizer = AdamW(model.parameters(), lr=1e-3)\n",
        "scheduler = get_cosine_with_hard_restarts_schedule_with_warmup(optimizer, num_warmup_steps=50, num_training_steps=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6jJdAguhKe9",
        "outputId": "80446dc1-a94f-4261-b0ca-01d6d8bb8944"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running 1 epoch\n",
            "Total Loss is 400.5715637207031\n",
            "Total Loss is 379.5576477050781\n",
            "Total Loss is 374.8067321777344\n",
            "Total Loss is 368.4908142089844\n",
            "Total Loss is 396.3864440917969\n",
            "Total Loss is 393.97509765625\n",
            "Total Loss is 396.3054504394531\n",
            "Total Loss is 385.0041198730469\n",
            "Total Loss is 394.3728942871094\n",
            "Total Loss is 401.3706970214844\n",
            "Running 2 epoch\n",
            "Total Loss is 377.47705078125\n",
            "Total Loss is 342.4095458984375\n",
            "Total Loss is 332.7271423339844\n",
            "Total Loss is 329.0473327636719\n",
            "Total Loss is 346.2327880859375\n",
            "Total Loss is 336.55633544921875\n",
            "Total Loss is 337.2743225097656\n",
            "Total Loss is 341.426513671875\n",
            "Total Loss is 334.7634582519531\n",
            "Total Loss is 325.00323486328125\n",
            "Total Loss is 344.3791198730469\n",
            "Running 3 epoch\n",
            "Total Loss is 308.1657409667969\n",
            "Total Loss is 325.9278564453125\n",
            "Total Loss is 318.2651672363281\n",
            "Total Loss is 325.0956726074219\n",
            "Total Loss is 337.4659118652344\n",
            "Total Loss is 341.8387145996094\n",
            "Total Loss is 339.9996643066406\n",
            "Total Loss is 359.1162109375\n",
            "Total Loss is 335.83154296875\n",
            "Total Loss is 349.7043762207031\n",
            "Total Loss is 327.04400634765625\n",
            "Running 4 epoch\n",
            "Total Loss is 315.7187805175781\n",
            "Total Loss is 323.90399169921875\n",
            "Total Loss is 343.4321594238281\n",
            "Total Loss is 331.3671875\n",
            "Total Loss is 335.82965087890625\n",
            "Total Loss is 319.8128662109375\n",
            "Total Loss is 323.83203125\n",
            "Total Loss is 326.67510986328125\n",
            "Total Loss is 358.6064453125\n",
            "Total Loss is 361.39068603515625\n",
            "Total Loss is 343.8352355957031\n"
          ]
        }
      ],
      "source": [
        "model = train(4, data_loader_sarcastic, 8, tokenizer, model, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rj5opIh2G_dh"
      },
      "outputs": [],
      "source": [
        "def save_model(model, name):\n",
        "\ttorch.save(model.state_dict(), f\"/content/{name}.pt\")\n",
        "\treturn\n",
        "\n",
        "save_model(model, 'sarcastic')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6TupiLDpZDU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def choose_from_top_k_top_n(probs, k=50, p=0.8):\n",
        "  ind = np.argpartition(probs, -k)[-k:]\n",
        "  top_prob = probs[ind]\n",
        "  top_prob = {i: top_prob[idx] for idx,i in enumerate(ind)}\n",
        "  sorted_top_prob = {k: v for k, v in sorted(top_prob.items(), key=lambda item: item[1], reverse=True)}\n",
        "\n",
        "  t=0\n",
        "  f=[]\n",
        "  pr = []\n",
        "  for k,v in sorted_top_prob.items():\n",
        "    t+=v\n",
        "    f.append(k)\n",
        "    pr.append(v)\n",
        "    if t>=p:\n",
        "      break\n",
        "  top_prob = pr / np.sum(pr)\n",
        "  token_id = np.random.choice(f, 1, p = top_prob)\n",
        "\n",
        "  return int(token_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "me9-T5RpOrME"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "import torch\n",
        "\n",
        "gc.collect()\n",
        "\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lntmfvwhvOUg"
      },
      "outputs": [],
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "\n",
        "tokenizer_sarcastic = GPT2Tokenizer.from_pretrained('gpt2-medium')\n",
        "model_sarcastic = GPT2LMHeadModel.from_pretrained('gpt2-medium')\n",
        "tokenizer_non_sarcastic = GPT2Tokenizer.from_pretrained('gpt2-medium')\n",
        "model_non_sarcastic = GPT2LMHeadModel.from_pretrained('gpt2-medium')\n",
        "\n",
        "model_sarcastic_path = f\"/content/drive/MyDrive/GPT2Sarcasm/sarcastic.pt\"\n",
        "model_non_sarcastic_path = f\"/content/drive/MyDrive/GPT2Sarcasm/non-sarcastic.pt\"\n",
        "\n",
        "model_sarcastic.load_state_dict(torch.load(model_sarcastic_path))\n",
        "model_non_sarcastic.load_state_dict(torch.load(model_non_sarcastic_path))\n",
        "\n",
        "model_sarcastic = model_sarcastic.to(device)\n",
        "model_non_sarcastic = model_non_sarcastic.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzW6cjmiqiUy"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def generate(tokenizer, model, sentences, label):\n",
        "\tresult = []\n",
        "\twith torch.no_grad():\n",
        "\t  for idx in tqdm(range(sentences)):\n",
        "\t\t  finished = False\n",
        "\t\t  cur_ids = torch.tensor(tokenizer.encode(label)).unsqueeze(0).to(device)\n",
        "\t\t  for i in range(100):\n",
        "\t\t\t  outputs = model(cur_ids, labels=cur_ids)\n",
        "\t\t\t  loss, logits = outputs[:2]\n",
        "\n",
        "\t\t\t  softmax_logits = torch.softmax(logits[0,-1], dim=0)\n",
        "\n",
        "\t\t\t  if i < 5:\n",
        "\t\t\t\t  n = 10\n",
        "\t\t\t  else:\n",
        "\t\t\t\t  n = 5\n",
        "\n",
        "\t\t\t  next_token_id = choose_from_top_k_top_n(softmax_logits.to(device).cpu().numpy())\n",
        "\t\t\t  cur_ids = torch.cat([cur_ids, torch.ones((1,1)).long().to(device) * next_token_id], dim = 1)\n",
        "\n",
        "\t\t\t  if next_token_id in tokenizer.encode('<|endoftext|>'):\n",
        "\t\t\t\t  finished = True\n",
        "\t\t\t\t  break\n",
        "\n",
        "\t\t  if finished:\t          \n",
        "\t\t\t  output_list = list(cur_ids.squeeze().to(device).cpu().numpy())\n",
        "\t\t\t  output_text = tokenizer.decode(output_list)\n",
        "\t\t\t  result.append(output_text)\n",
        "\t\t  else:\n",
        "\t\t\t  output_list = list(cur_ids.squeeze().to(device).cpu().numpy())\n",
        "\t\t\t  output_text = tokenizer.decode(output_list)\n",
        "\t\t\t  result.append(output_text)\n",
        "\t  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMm1IPjuub3o",
        "outputId": "ee54799e-032b-498d-b772-ca049c2bf13d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [17:34<00:00,  3.79it/s]\n"
          ]
        }
      ],
      "source": [
        "SAR = generate(tokenizer_sarcastic, model_sarcastic, 4000, 'SAR')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qESIFQYQPYzD"
      },
      "outputs": [],
      "source": [
        "f = open('/content/SAR.txt', 'w')\n",
        "for l in SAR:\n",
        "  f.write(l.replace('SAR', '').replace('<|endoftext|>', '').replace(\"\\n\", \"\").replace(\",\", \" \"))\n",
        "  f.write(\"\\n\")\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Q4Kg3-gyB_y",
        "outputId": "99f48f1a-b6b7-4347-daf7-ed59168ab602"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [28:44<00:00,  2.32it/s]\n"
          ]
        }
      ],
      "source": [
        "NON = generate(tokenizer_non_sarcastic, model_non_sarcastic, 4000, 'NON')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItH3hgthciTJ",
        "outputId": "026eae78-9bc2-4954-94b9-e63dbff4a89c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['NON mean there be not an ever a good idea not try all your food by hand i want my entire food turn out to be cooked on the <|endoftext|>',\n",
              " 'NON <|endoftext|>',\n",
              " 'NON be the same reason that it be night again im not get to think that it wasnt get to do and then im not get to think that it wasnt get to do it yet <|endoftext|>',\n",
              " 'NON my body to show on the air in the summer please you want to see the body again <|endoftext|>',\n",
              " 'NON wanna move to something really sad like you dont wanna move it like you want to move to be sad and sad people <|endoftext|>']"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "NON[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRNJwpEBcjte"
      },
      "outputs": [],
      "source": [
        "f = open('/content/NON.txt', 'w')\n",
        "for l in NON:\n",
        "  f.write(l.replace('NON', '').replace('<|endoftext|>', '').replace(\"\\n\", \"\").replace(\",\", \" \"))\n",
        "  f.write(\"\\n\")\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ot4WI_kqiseO",
        "outputId": "81c44a2f-72ec-4ee7-b463-53f3bb6ad25d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7186\n"
          ]
        }
      ],
      "source": [
        "data = { \"tweet\": [] , \"label\": [] }\n",
        "\n",
        "for l in NON:\n",
        "  tweet = l.replace('NON', '').replace('<|endoftext|>', '').replace(\"\\n\", \"\")\n",
        "  if tweet == \"\" or tweet == \" \" or \"\\n\" in tweet:\n",
        "    pass\n",
        "  else:\n",
        "    if tweet[0] == ' ':\n",
        "      data[\"tweet\"].append(tweet[1:])\n",
        "    else:\n",
        "      data[\"tweet\"].append(tweet)\n",
        "    data[\"label\"].append(0)\n",
        "\n",
        "for l in SAR:\n",
        "  tweet = l.replace('SAR', '').replace('<|endoftext|>', '').replace(\"\\n\", \"\")\n",
        "  if tweet == \"\" or tweet == \" \" or \"\\n\" in tweet:\n",
        "    pass\n",
        "  else:\n",
        "    if tweet[0] == ' ':\n",
        "      data[\"tweet\"].append(tweet[1:])\n",
        "    else:\n",
        "      data[\"tweet\"].append(tweet)\n",
        "    data[\"label\"].append(1)\n",
        "\n",
        "print(len(data[\"tweet\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1W2EEdBpoAK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pTc8ZKXr5yr"
      },
      "outputs": [],
      "source": [
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "df.to_csv(\"/content/gpt.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "GPT_2DataAugmentor.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
